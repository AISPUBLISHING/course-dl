{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, w1, w2, b = 6, 5, 3, 1, -25\n",
    "\n",
    "x1*w1 + x2*w2 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron(x,W,b):\n",
    "    return np.matmul(x,W)+b >= 0\n",
    "\n",
    "\n",
    "x = [6,2,4,2,7,8]\n",
    "W = [3,1,1,9,5,3]\n",
    "b = -25\n",
    "perceptron(x,W,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perceptron Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\mg\\Desktop\\intro to DL\\data.xlsx\", header=None)\n",
    "X = np.array([df[0], df[1]])\n",
    "y = np.array(df[2])\n",
    "\n",
    "plt.scatter(X[0][np.where(y==1)], X[1][np.where(y==1)], color='blue')\n",
    "plt.scatter(X[0][np.where(y==0)], X[1][np.where(y==0)], color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x, W, b):\n",
    "    return np.matmul(x,W)+b >= 0\n",
    "\n",
    "def perceptronStep(X, y, W, b, lr):\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i], W, b)\n",
    "        \n",
    "        if y[i] - y_hat == 1:\n",
    "            W[0] += X[i][0] * lr\n",
    "            W[1] += X[i][1] * lr\n",
    "            b += lr\n",
    "        elif y[i] - y_hat == -1:\n",
    "            W[0] -= X[i][0] * lr\n",
    "            W[1] -= X[i][1] * lr\n",
    "            b -= lr\n",
    "            \n",
    "    return W, b\n",
    "\n",
    "def trainPerceptron(X, y, lr, n_epochs):\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = 2\n",
    "    lines = []\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        lines.append((-W[0]/W[1], -b/W[1]))\n",
    "        W, b = perceptronStep(X, y, W, b, lr)\n",
    "        \n",
    "    return lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainPerceptron(X.T, y, lr=0.1, n_epochs=35)\n",
    "\n",
    "\n",
    "\n",
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "    \n",
    "for i in range(len(res)):\n",
    "    plt.scatter(X[0][np.where(y==1)], X[1][np.where(y==1)], color='blue')\n",
    "    plt.scatter(X[0][np.where(y==0)], X[1][np.where(y==0)], color='red')\n",
    "    abline(res[i][0], res[i][1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(L):\n",
    "    exps = np.exp(L)\n",
    "    sumOfExps = sum(exps)\n",
    "    \n",
    "    res = []\n",
    "    for i in exps:\n",
    "        res.append(i/sumOfExps)\n",
    "    return res\n",
    "\n",
    "softmax([2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(L):\n",
    "    exps = np.exp(L)\n",
    "    sumOfExps = sum(exps)\n",
    "    \n",
    "    return [i/sumOfExps for i in exps]\n",
    "\n",
    "softmax([2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crossEntropy(y, output):\n",
    "    return -y*np.log(output) - (1-y) * np.log(1-output)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def outputFormula(x, W, bias):\n",
    "    return sigmoid(np.dot(x,W)+bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Some helper functions for plotting and drawing lines\n",
    "\n",
    "def plot_points(X, y):\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'green', edgecolor = 'k')\n",
    "\n",
    "def display(m, b, color='g--'):\n",
    "    plt.xlim(-0.05,1.05)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    x = np.arange(-10, 10, 0.1)\n",
    "    plt.plot(x, m*x+b, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', header=None)\n",
    "X = np.array(data[[0,1]])\n",
    "y = np.array(data[2])\n",
    "plot_points(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def error_formula(y, output):\n",
    "    return -y*np.log(output) - (1-y) * np.log(1-output)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def outputFormula(x, W, bias):\n",
    "    return sigmoid(np.dot(x,W)+bias)\n",
    "\n",
    "def update_weights(x, y, weights, bias, lr):\n",
    "    output = outputFormula(x, weights, bias)\n",
    "    d_error = y - output\n",
    "    weights += lr * d_error * x\n",
    "    bias += lr * d_error\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "epochs = 400\n",
    "lr = 0.001\n",
    "\n",
    "def train(features, targets, epochs, lr):\n",
    "    errors = []\n",
    "    n_records, n_features = features.shape\n",
    "    \n",
    "    weights = np.random.normal(size = n_features)\n",
    "    bias = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for x, y in zip(features, targets):\n",
    "            output = outputFormula(x, weights, bias)\n",
    "            error = error_formula(y, output)\n",
    "            weights, bias = update_weights(x, y, weights, bias, lr)\n",
    "            \n",
    "        out = outputFormula(features, weights, bias)\n",
    "        loss = np.mean(error_formula(targets, out))\n",
    "        errors.append(loss)\n",
    "        \n",
    "        if e % (epochs/10) == 0:\n",
    "            print(\"\\n ========Epoch\",e,\"=========\")\n",
    "            print(\"Train Loss\", loss)\n",
    "            predictions = out > 0.5\n",
    "            accuracy = np.mean(predictions == targets)\n",
    "            print(\"Accuracy: \", accuracy)\n",
    "            \n",
    "            display(-weights[0]/weights[1], -bias/weights[1])\n",
    "            \n",
    "            \n",
    "    #Solution Boudary\n",
    "    plt.title(\"Solution Boudary\")\n",
    "    display(-weights[0]/weights[1], -bias/weights[1], 'black')\n",
    "    \n",
    "    plot_points(features, targets)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #Plotting the error\n",
    "    plt.title(\"Error Plot\")\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.plot(errors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X, y, epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('student_data.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_points(data):\n",
    "    X = np.array(data[[\"gre\",\"gpa\"]])\n",
    "    y = np.array(data[\"admit\"])\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
    "    plt.xlabel('Test (GRE)')\n",
    "    plt.ylabel('Grades (GPA)')\n",
    "    \n",
    "plot_points(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the ranks\n",
    "data_rank1 = data[data[\"rank\"]==1]\n",
    "data_rank2 = data[data[\"rank\"]==2]\n",
    "data_rank3 = data[data[\"rank\"]==3]\n",
    "data_rank4 = data[data[\"rank\"]==4]\n",
    "\n",
    "# Plotting the graphs\n",
    "plot_points(data_rank1)\n",
    "plt.title(\"Rank 1\")\n",
    "plt.show()\n",
    "plot_points(data_rank2)\n",
    "plt.title(\"Rank 2\")\n",
    "plt.show()\n",
    "plot_points(data_rank3)\n",
    "plt.title(\"Rank 3\")\n",
    "plt.show()\n",
    "plot_points(data_rank4)\n",
    "plt.title(\"Rank 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode = pd.concat([data, pd.get_dummies(data['rank'], prefix = 'rank')], axis = 1)\n",
    "hot_encode = hot_encode.drop('rank', axis = 1)\n",
    "hot_encode[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = hot_encode[:]\n",
    "\n",
    "processed_data['gpa'] = processed_data['gpa'] / processed_data['gpa'].max()\n",
    "processed_data['gre'] = processed_data['gre'] / processed_data['gre'].max()\n",
    "\n",
    "processed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(processed_data.index, size = int(len(processed_data)*0.9), replace = False)\n",
    "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
    "\n",
    "print(\"Size of Training:\", len(train_data))\n",
    "print(\"Size of Testing:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.drop('admit', axis=1)\n",
    "targets = train_data['admit']\n",
    "\n",
    "test_features = test_data.drop('admit', axis=1)\n",
    "targets_test = test_data['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_formula(y, output):\n",
    "    return -y*np.log(output) - (1-y) * np.log(1-output)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def error_term_formula(x, yhat, y):\n",
    "    return (y - yhat)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(features, targets, epochs = 1000, lr = 0.01):\n",
    "    np.random.seed(42)\n",
    "    n_records, n_features = features.shape\n",
    "    \n",
    "    weights = np.random.normal(size = n_features)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features.values, targets):\n",
    "            yhat = sigmoid(np.dot(x, weights))\n",
    "            error_term = error_term_formula(x, yhat, y)\n",
    "            del_w += error_term\n",
    "            \n",
    "        weights += lr * del_w\n",
    "    \n",
    "        if epoch % (epochs / 10) == 0:\n",
    "            out = (sigmoid(np.dot(features, weights)))\n",
    "            loss = np.mean(error_formula(targets, out))\n",
    "\n",
    "            print(\"Epoch:\", epoch)\n",
    "            print(\"Training Loss:\", loss,\"\\n==============\")\n",
    "    return weights\n",
    "\n",
    "weights = NN(features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = sigmoid(np.dot(test_features, weights))\n",
    "predictions = test_out > 0.5\n",
    "\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>98</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>110</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>139</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>16</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0     52            6.4           3.2            4.5           1.5   \n",
       "1     80            5.7           2.6            3.5           1.0   \n",
       "2     29            5.2           3.4            1.4           0.2   \n",
       "3     69            6.2           2.2            4.5           1.5   \n",
       "4     17            5.4           3.9            1.3           0.4   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145   98            6.2           2.9            4.3           1.3   \n",
       "146  110            7.2           3.6            6.1           2.5   \n",
       "147  139            6.0           3.0            4.8           1.8   \n",
       "148   16            5.7           4.4            1.5           0.4   \n",
       "149  145            6.7           3.3            5.7           2.5   \n",
       "\n",
       "             Species  \n",
       "0    Iris-versicolor  \n",
       "1    Iris-versicolor  \n",
       "2        Iris-setosa  \n",
       "3    Iris-versicolor  \n",
       "4        Iris-setosa  \n",
       "..               ...  \n",
       "145  Iris-versicolor  \n",
       "146   Iris-virginica  \n",
       "147   Iris-virginica  \n",
       "148      Iris-setosa  \n",
       "149   Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"Iris.csv\")\n",
    "iris = iris.sample(frac=1).reset_index(drop=True)\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4, 3.2, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.4, 3.9, 1.3, 0.4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris[['SepalLengthCm','SepalWidthCm', 'PetalLengthCm','PetalWidthCm']]\n",
    "X = np.array(X)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "Y = iris.Species\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1,1))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initWeights(nodes):\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        w = [[np.random.uniform(-1,1) for k in range(nodes[i-1] + 1)] for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(w))\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(x, weights, layers):\n",
    "    activations, layer_input = [x], x\n",
    "    \n",
    "    for j in range(layers):\n",
    "        activation = sigmoid(np.dot(layer_input, weights[j].T))\n",
    "        activations.append(activation)\n",
    "        layer_input = np.append(1, activation)\n",
    "        \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    return np.multiply(x, 1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(y, activations, weights, layers):\n",
    "    outputFinal = activations[-1]\n",
    "    error = np.matrix(y - outputFinal)\n",
    "    \n",
    "    for j in range(layers, 0, -1):\n",
    "        currentActivation = activations[j]\n",
    "        \n",
    "        if(j>1):\n",
    "            prevActivation = np.append(1, activations[j-1])\n",
    "        else:\n",
    "            prevActivation = activations[0]\n",
    "            \n",
    "        delta = np.multiply(error, sigmoidDerivative(currentActivation))\n",
    "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
    "\n",
    "        w = np.delete(weights[j-1], [0], axis=1)\n",
    "        error = np.dot(delta, w)\n",
    "    \n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, lr, weights):\n",
    "    layers = len(weights)\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], Y[i]\n",
    "        x = np.matrix(np.append(1,x))\n",
    "        activations = feedForward(x, weights, layers)\n",
    "        weights = backPropagation(y, activations, weights, layers)\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1, item)\n",
    "    \n",
    "    activations = feedForward(item, weights, layers)\n",
    "    output = activations[-1].A1\n",
    "    max_index = np.argmax(output)\n",
    "    \n",
    "    yhat = [0 for i in range(len(output))]\n",
    "    yhat[max_index] = 1\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, weights):\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        x, y = X[i], list(Y[i])\n",
    "        guess = predict(x, weights)\n",
    "        if(y == guess):\n",
    "            correct += 1\n",
    "    return correct/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X_train, Y_train, X_val = None, Y_val = None, epochs = 10, nodes = [], lr=0.15):\n",
    "    hidden_layers = len(nodes) - 1\n",
    "    weights = initWeights(nodes)\n",
    "    \n",
    "    for epoch in range(epochs+1):\n",
    "        weights = train(X_train, Y_train, lr, weights)\n",
    "        \n",
    "        if(epoch%20 == 0):\n",
    "            print(\"Epoch:\", epoch)\n",
    "            print(\"Training Accuracy:\", accuracy(X_train, Y_train, weights))\n",
    "            print(\"Validation Accuracy:\", accuracy(X_val, Y_val, weights))\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Accuracy: 0.34210526315789475\n",
      "Validation Accuracy: 0.15384615384615385\n",
      "Epoch: 20\n",
      "Training Accuracy: 0.9210526315789473\n",
      "Validation Accuracy: 0.8461538461538461\n",
      "Epoch: 40\n",
      "Training Accuracy: 0.8771929824561403\n",
      "Validation Accuracy: 0.7692307692307693\n",
      "Epoch: 60\n",
      "Training Accuracy: 0.9298245614035088\n",
      "Validation Accuracy: 0.8461538461538461\n",
      "Epoch: 80\n",
      "Training Accuracy: 0.9385964912280702\n",
      "Validation Accuracy: 0.8461538461538461\n",
      "Epoch: 100\n",
      "Training Accuracy: 0.9473684210526315\n",
      "Validation Accuracy: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "num_of_features = len(X[0])\n",
    "num_of_outputs = len(Y[0])\n",
    "\n",
    "layers = [num_of_features, 5, 8, num_of_outputs]\n",
    "lr, epochs = 0.15, 100\n",
    "\n",
    "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs = epochs, nodes = layers, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy:\", accuracy(X_test, Y_test, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
